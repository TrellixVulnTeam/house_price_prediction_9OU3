{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML Projects\\\\house_price_prediction\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"d:\\\\ML Projects\\\\house_price_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.config.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_config = config.get_model_evaluation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelEvaluationConfig(model_evaluation_file_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\model_evaluation\\\\2022-07-25_16-50-54\\\\model_evaluation.yaml', time_stamp='2022-07-25_16-50-54')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion_config = config.get_data_ingestion_config()\n",
    "data_validation_config = config.get_data_validation_config()\n",
    "data_transformation_config = config.get_data_transformation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Columns = [10]\n",
      "            Columns Names are : [Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'median_house_value', 'ocean_proximity'],\n",
      "      dtype='object')],\n",
      "            Numerical Feature Columns :[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']],\n",
      "            Categorical Features Column : [['ocean_proximity']],\n",
      "            Values in Ocean Proximity Column : [<1H OCEAN     7277\n",
      "INLAND        5262\n",
      "NEAR OCEAN    2124\n",
      "NEAR BAY      1847\n",
      "ISLAND           2\n",
      "Name: ocean_proximity, dtype: int64]\n",
      "            Validation Status =[True]\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "from housing.component.data_ingestion import DataIngestion\n",
    "from housing.component.data_validation import DataValidation\n",
    "from housing.component.data_transformation import DataTransformation\n",
    "\n",
    "data_ingestion = DataIngestion(data_ingestion_config)\n",
    "data_ingestion_artifact = data_ingestion.initiate_data_ingestion()\n",
    "\n",
    "data_validation = DataValidation(data_validation_config,data_ingestion_artifact)\n",
    "data_validation_artifact = data_validation.initiate_data_validation()\n",
    "\n",
    "data_transformation = DataTransformation(config ,data_transformation_config=data_transformation_config,data_ingestion_artifact=data_ingestion_artifact,data_validation_artifact=data_validation_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation_artifact = data_transformation.initiate_data_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformationArtifact(is_transformed=True, transformed_train_file_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\data_transformation\\\\2022-07-25_16-50-54\\\\transformed_data\\\\train\\\\housing.npz', transformed_test_file_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\data_transformation\\\\2022-07-25_16-50-54\\\\transformed_data\\\\test\\\\housing.npz', message='Data transformation done successfult', preprocessed_object_file_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\data_transformation\\\\2022-07-25_16-50-54\\\\preprocessed\\\\preprocessed.pkl')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformation_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer_config = config.get_model_trainer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelTrainerConfig(trained_model_file_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\model_trainer\\\\2022-07-25_16-50-54\\\\trained_model\\\\model.pkl', base_accuracy=0.6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.component.model_trainer import ModelTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training = ModelTraining(model_training_config=model_trainer_config,data_transformation_artifact=data_transformation_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True}\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.6s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.5s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.5s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.2s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.2s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.9s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.5s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   7.2s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.5s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.9s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.7s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.8s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.8s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.6s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.8s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.5s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.8s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   8.5s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   6.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.9s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.9s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.6s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.5s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.5s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.9s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.2s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.3s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.1s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.4s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.5s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.3s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.2s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.1s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   9.2s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   9.3s\n"
     ]
    }
   ],
   "source": [
    "metric_info = model_training.get_matric_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricInfoArtifact(model_name='LinearRegression(fit_intercept=False)', model_object=LinearRegression(fit_intercept=False), train_rmse=4709785076.060029, test_rmse=4477408708.672432, train_accuracy=0.6481553634454353, test_accuracy=0.6564599764795922, model_accuracy=0.6522812381877459, index_number=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = model_training.get_model_training_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<housing.entity.model_factory.ModelFactory at 0x1e69825af70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True}\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.0s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.0s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.2s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.6s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   8.5s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.6s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.6s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=  10.5s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=  11.5s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.8s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.6s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.5s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.8s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.9s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.5s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.7s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   9.0s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   9.4s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.5s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.5s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.5s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.1s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.3s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.3s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.2s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.4s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.4s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   9.2s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.7s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.0s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.2s\n",
      "{'fit_intercept': True}\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.3s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.0s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=40; total time=   3.0s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.2s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.4s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.4s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   7.1s\n",
      "[CV] END ................min_samples_leaf=2, n_estimators=80; total time=   6.3s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.8s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.7s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=   9.8s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=  11.2s\n",
      "[CV] END ...............min_samples_leaf=2, n_estimators=120; total time=  10.9s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=40; total time=   2.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.5s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.5s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.7s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   5.8s\n",
      "[CV] END ................min_samples_leaf=4, n_estimators=80; total time=   6.2s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.8s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.7s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.5s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.7s\n",
      "[CV] END ...............min_samples_leaf=4, n_estimators=120; total time=   8.5s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.5s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=40; total time=   2.6s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.9s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   6.5s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.4s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   5.4s\n",
      "[CV] END ................min_samples_leaf=6, n_estimators=80; total time=   6.6s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.5s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.3s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.2s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.7s\n",
      "[CV] END ...............min_samples_leaf=6, n_estimators=120; total time=   8.1s\n"
     ]
    }
   ],
   "source": [
    "model_training_artifact = model_training.initiate_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelTrainerArtifact(is_trained=True, message='Model Trained successfully', trained_model_file_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\model_trainer\\\\2022-07-25_16-50-54\\\\trained_model\\\\model.pkl', train_rmse=4709785076.060029, test_rmse=4477408708.672432, train_accuracy=0.6481553634454353, test_accuracy=0.6564599764795922, model_accuracy=0.6522812381877459)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_training_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.component.model_evaluation import ModelEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_evaluation = ModelEvaluation(model_evaluation_config=model_evaluation_config,\n",
    "model_training_artifact=model_training_artifact,data_ingestion_artifact=data_ingestion_artifact,data_validation_artifct=data_validation_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_artifact = mode_evaluation.initiate_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelEvaluationArtifact(is_model_accepted=True, evaluated_model_path='d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\model_trainer\\\\2022-07-25_16-50-54\\\\trained_model\\\\model.pkl')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML Projects\\\\house_price_prediction\\\\housing\\\\artifact\\\\model_trainer\\\\2022-07-25_16-50-54\\\\trained_model\\\\model.pkl'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation_artifact.evaluated_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExceptionHendler",
     "evalue": "error occure in file : [d:\\ML Projects\\house_price_prediction\\housing\\pipeline\\pipeline.py]\n        at Try block line Number : [80] and\n        Exception_block_line_number : [87]\n          Error_message is : [__init__() got an unexpected keyword argument 'data_validation_artifact']        \n        ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\ML Projects\\house_price_prediction\\housing\\pipeline\\pipeline.py:80\u001b[0m, in \u001b[0;36mPipeline.start_model_evaluation\u001b[1;34m(self, data_ingestion_artifact, data_validation_artifact, model_trainer_artifact)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     model_eval \u001b[39m=\u001b[39m ModelEvaluation(\n\u001b[0;32m     81\u001b[0m         model_evaluation_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget_model_evaluation_config(),\n\u001b[0;32m     82\u001b[0m         data_ingestion_artifact\u001b[39m=\u001b[39;49mdata_ingestion_artifact,\n\u001b[0;32m     83\u001b[0m         data_validation_artifact\u001b[39m=\u001b[39;49mdata_validation_artifact,\n\u001b[0;32m     84\u001b[0m         model_trainer_artifact\u001b[39m=\u001b[39;49mmodel_trainer_artifact)\n\u001b[0;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m model_eval\u001b[39m.\u001b[39minitiate_model_evaluation()\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'data_validation_artifact'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExceptionHendler\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\ML Projects\\house_price_prediction\\notebook\\EDA3.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ML%20Projects/house_price_prediction/notebook/EDA3.ipynb#ch0000263?line=0'>1</a>\u001b[0m model_evaluation_artifact \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mstart_model_evaluation(data_ingestion_artifact\u001b[39m=\u001b[39;49mdata_ingestion_artifact,data_validation_artifact\u001b[39m=\u001b[39;49mdata_validation_artifact,model_trainer_artifact\u001b[39m=\u001b[39;49mmodel_training_artifact)\n",
      "File \u001b[1;32md:\\ML Projects\\house_price_prediction\\housing\\pipeline\\pipeline.py:87\u001b[0m, in \u001b[0;36mPipeline.start_model_evaluation\u001b[1;34m(self, data_ingestion_artifact, data_validation_artifact, model_trainer_artifact)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m model_eval\u001b[39m.\u001b[39minitiate_model_evaluation()\n\u001b[0;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m ExceptionHendler(e,sys) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mExceptionHendler\u001b[0m: error occure in file : [d:\\ML Projects\\house_price_prediction\\housing\\pipeline\\pipeline.py]\n        at Try block line Number : [80] and\n        Exception_block_line_number : [87]\n          Error_message is : [__init__() got an unexpected keyword argument 'data_validation_artifact']        \n        "
     ]
    }
   ],
   "source": [
    "model_evaluation_artifact = pipeline.start_model_evaluation(data_ingestion_artifact=data_ingestion_artifact,data_validation_artifact=data_validation_artifact,model_trainer_artifact=model_training_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelTrainer(model_trainer_config=model_trainer_config,data_transformation_artifact=data_transformation_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = model_training.get_model_training_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.entity.model_factory import ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = os.path.join(ROOT_DIR,CONFIG_DIR_NAME,MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory = ModelFactory(model_config_path=model_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file,test_file =model_training.get_train_and_test_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = train_file[:,:-1],train_file[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file[:,:-1],train_file[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory.get_best_model(X=X,y=Y,base_accuracy=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory.grid_searched_best_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training.initiate_model_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file,test_file = model_training.get_train_and_test_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = model_training.get_model_training_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.grid_searched_best_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_training.get_best_model_with_accuray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searched_best_model_list:List[GridSearchedBestModel]=best_model.grid_searched_best_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grid_searched_best_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_accuracy = model_trainer_config.base_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test = train_file[:,:-1],train_file[:,-1],test_file[:,:-1],test_file[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searched_best_model_list:List[GridSearchedBestModel]=model_object.grid_searched_best_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grid_searched_best_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regression_model(model_list=model_list,X_train=x_train,y_train=y_train,X_test=x_test,y_test=y_test,base_accuracy=base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matric_info():\n",
    "        try:\n",
    "\n",
    "            \n",
    "\n",
    "            x_train,y_train,x_test,y_test = train_file[:,:-1],train_file[:,-1],test_file[:,:-1],test_file[:,-1]\n",
    "\n",
    "            base_accuracy = model_trainer_config.base_accuracy\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            grid_searched_best_model_list:List[GridSearchedBestModel]=model_object.grid_searched_best_model_list\n",
    "\n",
    "            model_list = [model.best_model for model in grid_searched_best_model_list ]\n",
    "\n",
    "            metric_info:MetricInfoArtifact = evaluate_regression_model(model_list=model_list,X_train=x_train,y_train=y_train,X_test=x_test,y_test=y_test,base_accuracy=base_accuracy)\n",
    "\n",
    "            return metric_info\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ExceptionHendler(e,sys) from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_matric_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matric_info = model_training.get_matric_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_file_path = model_training.get_trained_model_file_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_artifact = model_training.initiate_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = schema[NUMERICAL_COLUMN_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.entity.housing_predictor import HousingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = HousingData(-121.46,38.52,29.0,3873.0,797.0,2237.0,706.0,2.1736,\"INLAND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data.get_housing_data_as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data.get_housing_input_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.entity.housing_predictor import HousingPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (1,5,8,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "a = namedtuple(\"a\",['b','d','e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a(b=5,d='6',e='8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictor = HousingPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = schema[CATEGORICAL_COLUMN_KEY]\n",
    "\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from housing.logger import logging\n",
    "from housing.exception import ExceptionHendler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True,\n",
    "                 total_rooms_ix=3,\n",
    "                 population_ix=5,\n",
    "                 households_ix=6,\n",
    "                 total_bedrooms_ix=4, columns=None):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        add_bedrooms_per_room: bool\n",
    "        total_rooms_ix: int index number of total rooms columns\n",
    "        population_ix: int index number of total population columns\n",
    "        households_ix: int index number of  households columns\n",
    "        total_bedrooms_ix: int index number of bedrooms columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.columns = columns\n",
    "            if self.columns is not None:\n",
    "                total_rooms_ix = self.columns.index(COLUMN_TOTAL_ROOMS)\n",
    "                population_ix = self.columns.index(COLUMN_POPULATION)\n",
    "                households_ix = self.columns.index(COLUMN_HOUSEHOLDS)\n",
    "                total_bedrooms_ix = self.columns.index(COLUMN_TOTAL_BEDROOM)\n",
    "\n",
    "            self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "            self.total_rooms_ix = total_rooms_ix\n",
    "            self.population_ix = population_ix\n",
    "            self.households_ix = households_ix\n",
    "            self.total_bedrooms_ix = total_bedrooms_ix\n",
    "        except Exception as e:\n",
    "            raise ExceptionHendler(e, sys) from e\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            room_per_household = X[:, self.total_rooms_ix] / \\\n",
    "                                 X[:, self.households_ix]\n",
    "            population_per_household = X[:, self.population_ix] / \\\n",
    "                                       X[:, self.households_ix]\n",
    "            if self.add_bedrooms_per_room:\n",
    "                bedrooms_per_room = X[:, self.total_bedrooms_ix] / \\\n",
    "                                    X[:, self.total_rooms_ix]\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household, bedrooms_per_room]\n",
    "            else:\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household]\n",
    "\n",
    "            return generated_feature\n",
    "        except Exception as e:\n",
    "            raise ExceptionHendler(e, sys) from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TOTAL_ROOMS = \"total_rooms\"\n",
    "COLUMN_POPULATION = \"population\"\n",
    "COLUMN_HOUSEHOLDS = \"households\"\n",
    "COLUMN_TOTAL_BEDROOM = \"total_bedrooms\"\n",
    "\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True,\n",
    "                 total_rooms_ix=3,\n",
    "                 population_ix=5,\n",
    "                 households_ix=6,\n",
    "                 total_bedrooms_ix=4, columns=None):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        add_bedrooms_per_room: bool\n",
    "        total_rooms_ix: int index number of total rooms columns\n",
    "        population_ix: int index number of total population columns\n",
    "        households_ix: int index number of  households columns\n",
    "        total_bedrooms_ix: int index number of bedrooms columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.columns = columns\n",
    "            if self.columns is not None:\n",
    "                total_rooms_ix = self.columns.index(COLUMN_TOTAL_ROOMS)\n",
    "                population_ix = self.columns.index(COLUMN_POPULATION)\n",
    "                households_ix = self.columns.index(COLUMN_HOUSEHOLDS)\n",
    "                total_bedrooms_ix = self.columns.index(COLUMN_TOTAL_BEDROOM)\n",
    "\n",
    "            self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "            self.total_rooms_ix = total_rooms_ix\n",
    "            self.population_ix = population_ix\n",
    "            self.households_ix = households_ix\n",
    "            self.total_bedrooms_ix = total_bedrooms_ix\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            room_per_household = X[:, self.total_rooms_ix] / \\\n",
    "                                 X[:, self.households_ix]\n",
    "            population_per_household = X[:, self.population_ix] / \\\n",
    "                                       X[:, self.households_ix]\n",
    "            if self.add_bedrooms_per_room:\n",
    "                bedrooms_per_room = X[:, self.total_bedrooms_ix] / \\\n",
    "                                    X[:, self.total_rooms_ix]\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household, bedrooms_per_room]  ## Here _c is Concatination symbol\n",
    "            else:\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household]\n",
    "\n",
    "            return generated_feature\n",
    "        except Exception as e:\n",
    "            raise ExceptionHendler(e,sys) from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator = FeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('feature_generator', FeatureGenerator(\n",
    "                    add_bedrooms_per_room=data_transformation_config.add_bedroom_per_room,\n",
    "                    columns=numerical_columns\n",
    "                )),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]\n",
    "            )\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "                 ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                 ('one_hot_encoder', OneHotEncoder()),\n",
    "                 ('scaler', StandardScaler(with_mean=False))\n",
    "            ]\n",
    "            )\n",
    "\n",
    "logging.info(f\"Categorical columns: {categorical_columns}\")\n",
    "logging.info(f\"Numerical columns: {numerical_columns}\")\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "                ('num_pipeline', num_pipeline, numerical_columns),\n",
    "                ('cat_pipeline', cat_pipeline, categorical_columns),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[: ,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = schema[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = df.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame = df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame[\"targets\"] = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.dashboard import Dashboard\n",
    "from evidently.dashboard.tabs import (\n",
    "    DataDriftTab,\n",
    "    CatTargetDriftTab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_drift_report = Dashboard(tabs=[DataDriftTab()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_drift_report.calculate(df_frame[:100], df_frame[100:], column_mapping = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"report_iris.html\",\"w\") as report:\n",
    "    #report.write(\"hello\")\n",
    "    iris_data_drift_report.save(\"report_iris.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_and_target_drift_report.calculate(df_frame[:100], df_frame[100:], column_mapping =df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_and_target_drift_report.calculate(df_frame[:100], df_frame[100:], column_mapping = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"d:\\\\ML Projects\\\\house_price_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = r\"D:\\ML Projects\\house_price_prediction\\housing\\artifact\\data_ingestion\\2022-07-13_11-44-05\\ingested_data\\train\\housing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns = \"median_house_value\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[[\"median_house_value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [feature for feature in X.columns if X[feature].dtypes!=\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [feature for feature in X.columns if X[feature].dtypes==\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_df = X.drop(columns = \"ocean_proximity\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer = SimpleImputer(strategy =\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer.fit(X_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer.transform(X_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer.fit_transform(X_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical_df = X[[\"ocean_proximity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer_cat = SimpleImputer(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer_cat.fit_transform(X_categorical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer_cat.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self,strategy = \"median\"):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def fit(self,x):\n",
    "\n",
    "        self.features = x.columns\n",
    "        self.statistics_ = []\n",
    "\n",
    "        for feature in self.features:\n",
    "\n",
    "            self.statistics_.append(x[feature].median())\n",
    "\n",
    "        return self.statistics_\n",
    "\n",
    "    def trainsform(self,x:pd.DataFrame):\n",
    "        self.x=  x\n",
    "\n",
    "        for idx, column in enumerate(self.x.columns):\n",
    "            x[column] = x[column].fillna(self.statistics_[idx])\n",
    "\n",
    "        return self.x\n",
    "\n",
    "    def fit_transform(self,x:pd.DataFrame):\n",
    "        self.x = x\n",
    "        result = self.trainsform(self.x)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator = FeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator.fit(X_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator.trainsform(X_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator.fit_transform(X_numeric_df).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = {\"name\":[\"sumit\",\"sanjay\",\"yadav\",\"sudhir\",\"vikash\",\"arun\"],\"marks\":[45,49,55,75,29,66],\"subjects\":['a','b','c','d','e','f']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ranks\"] = [2,4,5,3,1,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"contact\"] = [44666,6445,\"nan\",64,\"nan\",566664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG = \"longitude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.index(LONG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.util.util import read_yaml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_file_path = r\"D:\\ML Projects\\house_price_prediction\\config\\schema.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = read_yaml_file(file_path=schema_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = schema[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.index(\"total_rooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TOTAL_ROOMS = \"total_rooms\"\n",
    "COLUMN_POPULATION = \"population\"\n",
    "COLUMN_HOUSEHOLDS = \"households\"\n",
    "COLUMN_TOTAL_BEDROOM = \"total_bedrooms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "       'median_house_value', 'ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.index(COLUMN_TOTAL_ROOMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TOTAL_ROOMS = \"total_rooms\"\n",
    "COLUMN_POPULATION = \"population\"\n",
    "COLUMN_HOUSEHOLDS = \"households\"\n",
    "COLUMN_TOTAL_BEDROOM = \"total_bedrooms\"\n",
    "\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True,\n",
    "                 total_rooms_ix=3,\n",
    "                 population_ix=5,\n",
    "                 households_ix=6,\n",
    "                 total_bedrooms_ix=4, columns=None):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        add_bedrooms_per_room: bool\n",
    "        total_rooms_ix: int index number of total rooms columns\n",
    "        population_ix: int index number of total population columns\n",
    "        households_ix: int index number of  households columns\n",
    "        total_bedrooms_ix: int index number of bedrooms columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "                              'total_bedrooms', 'population', 'households', 'median_income',\n",
    "                               'median_house_value', 'ocean_proximity']\n",
    "            if self.columns is not None:\n",
    "                total_rooms_ix = self.columns.index(COLUMN_TOTAL_ROOMS)\n",
    "                population_ix = self.columns.index(COLUMN_POPULATION)\n",
    "                households_ix = self.columns.index(COLUMN_HOUSEHOLDS)\n",
    "                total_bedrooms_ix = self.columns.index(COLUMN_TOTAL_BEDROOM)\n",
    "\n",
    "            self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "            self.total_rooms_ix = total_rooms_ix\n",
    "            self.population_ix = population_ix\n",
    "            self.households_ix = households_ix\n",
    "            self.total_bedrooms_ix = total_bedrooms_ix\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            room_per_household = X[:, self.total_rooms_ix] / \\\n",
    "                                 X[:, self.households_ix]\n",
    "            population_per_household = X[:, self.population_ix] / \\\n",
    "                                       X[:, self.households_ix]\n",
    "            if self.add_bedrooms_per_room:\n",
    "                bedrooms_per_room = X[:, self.total_bedrooms_ix] / \\\n",
    "                                    X[:, self.total_rooms_ix]\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household, bedrooms_per_room]  ## Here _c is Concatination symbol\n",
    "            else:\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household]\n",
    "\n",
    "            return generated_feature\n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = FeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.add_bedrooms_per_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.total_rooms_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.households_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " num_pipeline = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('feature_generator', FeatureGenerator(\n",
    "                    add_bedrooms_per_room=self.data_transformation_config.add_bedroom_per_room,\n",
    "                    columns=numerical_columns\n",
    "                )),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]\n",
    "            )\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "                 ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                 ('one_hot_encoder', OneHotEncoder()),\n",
    "                 ('scaler', StandardScaler(with_mean=False))\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Categorical columns: {categorical_columns}\")\n",
    "            logging.info(f\"Numerical columns: {numerical_columns}\")\n",
    "\n",
    "\n",
    "            preprocessing = ColumnTransformer([\n",
    "                ('num_pipeline', num_pipeline, numerical_columns),\n",
    "                ('cat_pipeline', cat_pipeline, categorical_columns),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.config.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation_config = config.get_data_transformation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('scaler', StandardScaler(with_mean=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline(steps=[\n",
    "                 ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                 ('one_hot_encoder', OneHotEncoder()),\n",
    "                 ('scaler', StandardScaler(with_mean=False))\n",
    "            ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms',\n",
    " 'population',\n",
    " 'households',\n",
    " 'median_income',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer([\n",
    "                ('num_pipeline', num_pipeline, numerical_columns),\n",
    "                ('cat_pipeline', cat_pipeline, categorical_columns),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.tabs import DataDriftTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard =Dashboard(tabs=[DataDriftTab()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation_config = config.get_data_validation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.component.data_ingestion import DataIngestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion = DataIngestion(data_ingestion_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion_artifact = data_ingestion.initiate_data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.component.data_validation import DataValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation = DataValidation(data_validation_config,data_ingestion_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = data_validation.get_train_df_and_test_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard =Dashboard(tabs=[DataDriftTab()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.calculate(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_page_file_path = r\"D:\\ML Projects\\house_price_prediction\\report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.save(report_page_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = train_df,test_df\n",
    "            dashboard.calculate(train_df,test_df)\n",
    "            report_page_file_path = data_validation_config.report_page_file_path\n",
    "            report_page_dir = os.path.dirname(report_page_file_path)\n",
    "            os.makedirs(report_page_dir,exist_ok=True)\n",
    "            dashboard.save(report_page_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.model_profile import Profile\n",
    "from evidently.model_profile.sections import DataDriftProfileSection\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.dashboard.tabs import DataDriftTab\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = Profile(sections=[DataDriftProfileSection()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.calculate(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = json.loads(profile.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"report_file\",\"w\") as report_a:\n",
    "    json.dump(report,report_a,indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dashboard = Dashboard(tabs=[DataDriftTab()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dashboard.calculate(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_b = data_drift_dashboard.show(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(report_b,\"rb\") as report_c:\n",
    "    dill.dump(report_c,report_page_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard =Dashboard(tabs=[DataDriftTab()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.calculate(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_page_file_path=r\"D:\\ML Projects\\house_price_prediction\\report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D:\\ML Projects\\house_price_prediction\\report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(report_page_file_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.save(report_page_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dashboard.show(mode=’inline’) ## for showing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjeev@ineuron.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fd6d81f1e5272f29fb2ced79108f36eae0dd168f0f3af2056730384b76497e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
